{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the lung segmentation dataset from Kaggle and the UNET architecture to train a model to segment lung scans. The dataset has two labels; normal and tubercolosis. The model learns which is which and is able to segment the lungs so that it is clear to people viewing the scans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision \n",
    "import os\n",
    "import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Image preprocessing libraries\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 32\n",
    "LR = 0.001\n",
    "dir_path = r'C:\\Users\\Sam\\OneDrive - Monash University\\Monash - Uni\\DeepNeuron\\Training Project\\Begineer Projects\\Medical MNIST Data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n",
      "{'AbdomenCT': 0, 'BreastMRI': 1, 'CXR': 2, 'ChestCT': 3, 'Hand': 4, 'HeadCT': 5}\n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Load entire dataset\n",
    "dataset = ImageFolder(root=dir_path, transform=transform)\n",
    "\n",
    "# Check class names and label mapping\n",
    "print(dataset.classes)  # ['feet', 'hand', 'head']\n",
    "print(dataset.class_to_idx)  # {'feet': 0, 'hand': 1, 'head': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data samples:  41267\n",
      "Val data samples:  11790\n",
      "Test data samples:  5897\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train, validation and test: (70%, 20%, 10%)\n",
    "\n",
    "train_split = int(0.7*len(dataset))\n",
    "val_split = int(0.2*len(dataset))\n",
    "test_split = len(dataset) - train_split - val_split\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = random_split(dataset, [train_split, val_split, test_split])\n",
    "\n",
    "print(\"Training data samples: \", len(train_data))\n",
    "print(\"Val data samples: \", len(val_data))\n",
    "print(\"Test data samples: \", len(test_data))\n",
    "\n",
    "\n",
    "train_load = DataLoader(train_data, batch_size=BATCH, shuffle=True)\n",
    "val_load = DataLoader(val_data, batch_size=BATCH, shuffle=False)\n",
    "test_load = DataLoader(test_data, batch_size=BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 1, 256, 256])\n",
      "Label batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_load))\n",
    "print(\"Image batch shape:\", images.shape)  # Expected: (batch_size, 1, 224, 224)\n",
    "print(\"Label batch shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,664\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-4         [-1, 64, 128, 128]               0\n",
      "            Conv2d-5        [-1, 128, 128, 128]         204,928\n",
      "       BatchNorm2d-6        [-1, 128, 128, 128]             256\n",
      "              ReLU-7        [-1, 128, 128, 128]               0\n",
      "         MaxPool2d-8          [-1, 128, 64, 64]               0\n",
      "            Conv2d-9          [-1, 256, 64, 64]         819,456\n",
      "      BatchNorm2d-10          [-1, 256, 64, 64]             512\n",
      "             ReLU-11          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-12          [-1, 256, 32, 32]               0\n",
      "           Linear-13                    [-1, 6]       1,572,870\n",
      "================================================================\n",
      "Total params: 2,599,814\n",
      "Trainable params: 2,599,814\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 182.00\n",
      "Params size (MB): 9.92\n",
      "Estimated Total Size (MB): 192.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, batch_size=BATCH):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Input size into the model will be: (bs, c, h, w)\n",
    "        self.num_classes = num_classes\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 5, 1, 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, 5, 1, 2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 5, 1, 2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc = nn.Linear(256 * 32 * 32, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten before FC layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Print a model summary showing the output dimensions and parameters passed through each layer. \n",
    "model = CNN(6)\n",
    "summary(model, (1, 256, 256))\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training: \n",
    "import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class TrainModel():\n",
    "    def __init__(self, model, optim, criterion, device):\n",
    "\n",
    "        self.optimizer = optim\n",
    "        self.criterion = criterion\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "    \n",
    "    def train_epoch(self, trainloader):\n",
    "\n",
    "        model = self.model.train()\n",
    "        progress = tqdm.tqdm(trainloader)\n",
    "        correct=0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch in progress:\n",
    "            # Prepare the data from the batch\n",
    "            data, label = batch\n",
    "            data, label = data.to(self.device), label.to(self.device)\n",
    "            \n",
    "            # Zero the gradients on the model\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Output a prediction\n",
    "            output = model(data)\n",
    "            loss = self.criterion(output, label)\n",
    "            loss.backward() # Back propagation through the model\n",
    "            self.optimizer.step()    # Updates parameters\n",
    "\n",
    "            \n",
    "            # compute training statistics\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item() # sum total loss in current epoch for print later\n",
    "            progress.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = running_loss / len(train_data)\n",
    "        avg_acc = correct / len(train_data)\n",
    "\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "    def eval_model(self, validloader):\n",
    "        \"\"\" \n",
    "        This function evaluates the model performance on the avl dataset and \n",
    "        updates hyperparameters in training. \n",
    "        \"\"\"\n",
    "        model=self.model.eval() # puts the model in validation mode\n",
    "        with torch.no_grad():   # No gradient calculation as no backward propagation\n",
    "            loss_val = 0.0\n",
    "            correct_val = 0\n",
    "\n",
    "        # Iterates through each batch in the data loader\n",
    "            for data in tqdm.tqdm(validloader):\n",
    "                batch, labels = data\n",
    "                batch, labels = batch.to(self.device), labels.to(self.device)   # Sends data to GPU if available\n",
    "                outputs = model(batch)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                loss_val += loss.item()\n",
    "            avg_loss_val = loss_val / len(val_data)\n",
    "            avg_acc_val = correct_val /len(val_data)\n",
    "\n",
    "        return avg_loss_val, avg_acc_val\n",
    "\n",
    "    def test(self, testloader):\n",
    "        \"\"\"\n",
    "        Loads in the test dataset and tests the model against unseen images\n",
    "        Returns the accuracy on test images\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        model=self.model.eval()\n",
    "        with torch.no_grad(): # no gradient calculation\n",
    "            for data in testloader:\n",
    "                batch, labels = data\n",
    "                batch, labels = batch.to(self.device), labels.to(self.device)\n",
    "                outputs = model(batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return ('Accuracy on the test images: %.2f %%' % (100 * correct / len(test_data)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "device = device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "CNN_model = TrainModel(model, optimizer, criterion, device)\n",
    "\n",
    "#acc log for graph\n",
    "epoch = 1\n",
    "simp_acc_hist = []\n",
    "simp_acc_hist_val =[]\n",
    "for e in range(epoch):\n",
    "  print(f'Epoch {e + 1}/{epoch}')\n",
    "  print('-' * 10)\n",
    "  simple_train_loss ,simple_train_acc= CNN_model.train_epoch(train_load)\n",
    "  simp_acc_hist.append(simple_train_acc)\n",
    "  print(f'Train loss {simple_train_loss} accuracy {simple_train_acc}')\n",
    "\n",
    "  simple_val_loss, simple_val_acc = CNN_model.eval_model(val_load)\n",
    "  simp_acc_hist_val.append(simple_val_acc)\n",
    "\n",
    "  print(f'Val loss {simple_val_loss} accuracy {simple_val_acc}')\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projects_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
